{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Foc_00fwTvY3"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "euboaVbsTvY5",
        "outputId": "4f4998a0-d387-4e03-dc6b-43def0108675"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"application_df\",\n  \"rows\": 34299,\n  \"fields\": [\n    {\n      \"column\": \"EIN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 245147183,\n        \"min\": 10520599,\n        \"max\": 996086871,\n        \"num_unique_values\": 34299,\n        \"samples\": [\n          271598055,\n          900109768,\n          352562499\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NAME\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19568,\n        \"samples\": [\n          \"LOCAL 12 USW GOODYEAR INSTITUTE FORCAREER DEVELOPMENT\",\n          \"INTERNATION ASSOCIATION OF ELECTRICAL INSPECTORS\",\n          \"BRICKLAYERS & ALLIED CRAFTWORKERS LOCAL 13 VACATION FUND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"APPLICATION_TYPE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"T10\",\n          \"T3\",\n          \"T6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AFFILIATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Independent\",\n          \"CompanySponsored\",\n          \"Other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASSIFICATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"C1500\",\n          \"C1000\",\n          \"C1570\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"USE_CASE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Preservation\",\n          \"Other\",\n          \"Heathcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORGANIZATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Co-operative\",\n          \"Corporation\",\n          \"Association\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"STATUS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"INCOME_AMT\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"1M-5M\",\n          \"1-9999\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SPECIAL_CONSIDERATIONS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASK_AMT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87130452,\n        \"min\": 5000,\n        \"max\": 8597806340,\n        \"num_unique_values\": 8747,\n        \"samples\": [\n          1328927,\n          42942\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IS_SUCCESSFUL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "application_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ac830673-f194-44dd-b4d0-0ba76424d4fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac830673-f194-44dd-b4d0-0ba76424d4fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac830673-f194-44dd-b4d0-0ba76424d4fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac830673-f194-44dd-b4d0-0ba76424d4fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40211597-715c-4710-b337-3dfd7107443f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40211597-715c-4710-b337-3dfd7107443f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40211597-715c-4710-b337-3dfd7107443f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Up_lJTlNTvY7"
      },
      "outputs": [],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(columns=['EIN', 'NAME'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "application_df.value_counts(\"IS_SUCCESSFUL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "rzHE25hxTvY7",
        "outputId": "691785c8-567d-43d6-a886-c48d40e218a8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFFILIATION</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>USE_CASE</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STATUS</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ASK_AMT</th>\n",
              "      <td>8747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "V5VeAlWoTvY7",
        "outputId": "2636b406-c038-4427-9db0-86461e953a9d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T3</th>\n",
              "      <td>27037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T4</th>\n",
              "      <td>1542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T6</th>\n",
              "      <td>1216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T5</th>\n",
              "      <td>1173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T19</th>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T8</th>\n",
              "      <td>737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T7</th>\n",
              "      <td>725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T10</th>\n",
              "      <td>528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T9</th>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T13</th>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T12</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T2</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T25</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T14</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T29</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T15</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T17</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "APPLICATION_TYPE\n",
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
        "application_df[\"APPLICATION_TYPE\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR0mGEMmTvY7",
        "outputId": "789547ef-117f-4595-dac7-74ec3cf4cad3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['T10', 'T9', 'T13', 'T12', 'T2', 'T25', 'T14', 'T29', 'T15', 'T17']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app_type_counts = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "app_type_counts.loc[app_type_counts < 550].index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "6UbC6FcFTvY8",
        "outputId": "cab1438d-cb9a-41cc-f3ee-f2c4cc5ed081"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T3</th>\n",
              "      <td>27037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T4</th>\n",
              "      <td>1542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T6</th>\n",
              "      <td>1216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T5</th>\n",
              "      <td>1173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T19</th>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T8</th>\n",
              "      <td>737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T7</th>\n",
              "      <td>725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "APPLICATION_TYPE\n",
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "Other      804\n",
              "T8         737\n",
              "T7         725\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "threshold = 550\n",
        "app_type_counts = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "application_types_to_replace = app_type_counts.loc[app_type_counts < threshold].index.tolist()\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "QjuJqpxQTvY8",
        "outputId": "76f645dc-8e9d-471e-f5e7-fe835121ba6f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C1000</th>\n",
              "      <td>17326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2000</th>\n",
              "      <td>6074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1200</th>\n",
              "      <td>4837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3000</th>\n",
              "      <td>1918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2100</th>\n",
              "      <td>1883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C4120</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C8210</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2561</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C4500</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2150</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "         ...  \n",
              "C4120        1\n",
              "C8210        1\n",
              "C2561        1\n",
              "C4500        1\n",
              "C2150        1\n",
              "Name: count, Length: 71, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
        "application_df[\"CLASSIFICATION\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N9Lm2yAqTvY8",
        "outputId": "62394d99-03ae-4308-a2e8-ec96a9d6a2c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C1000</th>\n",
              "      <td>17326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2000</th>\n",
              "      <td>6074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1200</th>\n",
              "      <td>4837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3000</th>\n",
              "      <td>1918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2100</th>\n",
              "      <td>1883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7000</th>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1700</th>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C4000</th>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C5000</th>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1270</th>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2700</th>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2800</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7100</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1300</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1280</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1230</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1400</th>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7200</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2300</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1240</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C8000</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7120</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1500</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1800</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C6000</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1250</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C8200</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1238</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1278</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1235</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1237</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7210</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2400</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1720</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C4100</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1257</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1600</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1260</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2710</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3200</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1234</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1246</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1267</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1256</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "C1230       36\n",
              "C1400       34\n",
              "C7200       32\n",
              "C2300       32\n",
              "C1240       30\n",
              "C8000       20\n",
              "C7120       18\n",
              "C1500       16\n",
              "C1800       15\n",
              "C6000       15\n",
              "C1250       14\n",
              "C8200       11\n",
              "C1238       10\n",
              "C1278       10\n",
              "C1235        9\n",
              "C1237        9\n",
              "C7210        7\n",
              "C2400        6\n",
              "C1720        6\n",
              "C4100        6\n",
              "C1257        5\n",
              "C1600        5\n",
              "C1260        3\n",
              "C2710        3\n",
              "C0           3\n",
              "C3200        2\n",
              "C1234        2\n",
              "C1246        2\n",
              "C1267        2\n",
              "C1256        2\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "class_counts = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "class_counts.loc[class_counts > 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "tA-ayaE4TvY8",
        "outputId": "4c826f56-9805-475e-90e8-741f67f4844b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C1000</th>\n",
              "      <td>17326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2000</th>\n",
              "      <td>6074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1200</th>\n",
              "      <td>4837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3000</th>\n",
              "      <td>1918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2100</th>\n",
              "      <td>1883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>1484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7000</th>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "Other     1484\n",
              "C7000      777\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "class_counts = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "classifications_to_replace = class_counts.loc[class_counts < 300].index.tolist()\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqIlaUVUTvY9",
        "outputId": "99c5e65a-6d78-4373-b44f-075d7a248b08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE',\n",
              "       'ORGANIZATION', 'STATUS', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS',\n",
              "       'ASK_AMT', 'IS_SUCCESSFUL'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "application_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCzMw57KTvY9",
        "outputId": "9bc290b9-a359-4613-c332-697a0ca0ba1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34299 entries, 0 to 34298\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   APPLICATION_TYPE        34299 non-null  object\n",
            " 1   AFFILIATION             34299 non-null  object\n",
            " 2   CLASSIFICATION          34299 non-null  object\n",
            " 3   USE_CASE                34299 non-null  object\n",
            " 4   ORGANIZATION            34299 non-null  object\n",
            " 5   STATUS                  34299 non-null  int64 \n",
            " 6   INCOME_AMT              34299 non-null  object\n",
            " 7   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
            " 8   ASK_AMT                 34299 non-null  int64 \n",
            " 9   IS_SUCCESSFUL           34299 non-null  int64 \n",
            "dtypes: int64(3), object(7)\n",
            "memory usage: 2.6+ MB\n"
          ]
        }
      ],
      "source": [
        "application_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xLY-n2sWTvY9"
      },
      "outputs": [],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "df_encoded = pd.get_dummies(application_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EBVCD5gTvY9",
        "outputId": "21de0777-2db8-4c2a-996c-8eea7a6f8995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34299 entries, 0 to 34298\n",
            "Data columns (total 44 columns):\n",
            " #   Column                        Non-Null Count  Dtype\n",
            "---  ------                        --------------  -----\n",
            " 0   STATUS                        34299 non-null  int64\n",
            " 1   ASK_AMT                       34299 non-null  int64\n",
            " 2   IS_SUCCESSFUL                 34299 non-null  int64\n",
            " 3   APPLICATION_TYPE_Other        34299 non-null  bool \n",
            " 4   APPLICATION_TYPE_T19          34299 non-null  bool \n",
            " 5   APPLICATION_TYPE_T3           34299 non-null  bool \n",
            " 6   APPLICATION_TYPE_T4           34299 non-null  bool \n",
            " 7   APPLICATION_TYPE_T5           34299 non-null  bool \n",
            " 8   APPLICATION_TYPE_T6           34299 non-null  bool \n",
            " 9   APPLICATION_TYPE_T7           34299 non-null  bool \n",
            " 10  APPLICATION_TYPE_T8           34299 non-null  bool \n",
            " 11  AFFILIATION_CompanySponsored  34299 non-null  bool \n",
            " 12  AFFILIATION_Family/Parent     34299 non-null  bool \n",
            " 13  AFFILIATION_Independent       34299 non-null  bool \n",
            " 14  AFFILIATION_National          34299 non-null  bool \n",
            " 15  AFFILIATION_Other             34299 non-null  bool \n",
            " 16  AFFILIATION_Regional          34299 non-null  bool \n",
            " 17  CLASSIFICATION_C1000          34299 non-null  bool \n",
            " 18  CLASSIFICATION_C1200          34299 non-null  bool \n",
            " 19  CLASSIFICATION_C2000          34299 non-null  bool \n",
            " 20  CLASSIFICATION_C2100          34299 non-null  bool \n",
            " 21  CLASSIFICATION_C3000          34299 non-null  bool \n",
            " 22  CLASSIFICATION_C7000          34299 non-null  bool \n",
            " 23  CLASSIFICATION_Other          34299 non-null  bool \n",
            " 24  USE_CASE_CommunityServ        34299 non-null  bool \n",
            " 25  USE_CASE_Heathcare            34299 non-null  bool \n",
            " 26  USE_CASE_Other                34299 non-null  bool \n",
            " 27  USE_CASE_Preservation         34299 non-null  bool \n",
            " 28  USE_CASE_ProductDev           34299 non-null  bool \n",
            " 29  ORGANIZATION_Association      34299 non-null  bool \n",
            " 30  ORGANIZATION_Co-operative     34299 non-null  bool \n",
            " 31  ORGANIZATION_Corporation      34299 non-null  bool \n",
            " 32  ORGANIZATION_Trust            34299 non-null  bool \n",
            " 33  INCOME_AMT_0                  34299 non-null  bool \n",
            " 34  INCOME_AMT_1-9999             34299 non-null  bool \n",
            " 35  INCOME_AMT_10000-24999        34299 non-null  bool \n",
            " 36  INCOME_AMT_100000-499999      34299 non-null  bool \n",
            " 37  INCOME_AMT_10M-50M            34299 non-null  bool \n",
            " 38  INCOME_AMT_1M-5M              34299 non-null  bool \n",
            " 39  INCOME_AMT_25000-99999        34299 non-null  bool \n",
            " 40  INCOME_AMT_50M+               34299 non-null  bool \n",
            " 41  INCOME_AMT_5M-10M             34299 non-null  bool \n",
            " 42  SPECIAL_CONSIDERATIONS_N      34299 non-null  bool \n",
            " 43  SPECIAL_CONSIDERATIONS_Y      34299 non-null  bool \n",
            "dtypes: bool(41), int64(3)\n",
            "memory usage: 2.1 MB\n"
          ]
        }
      ],
      "source": [
        "df_encoded.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "dd1Z3Q7oTvY-",
        "outputId": "5554606c-e550-461e-fd29-f3e5b8213d6d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_encoded"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e2a6fc1d-0369-4a35-ab4b-6f571b9ede08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_Other</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2a6fc1d-0369-4a35-ab4b-6f571b9ede08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2a6fc1d-0369-4a35-ab4b-6f571b9ede08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2a6fc1d-0369-4a35-ab4b-6f571b9ede08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-422f55fc-a4bd-4c76-961d-5382fd1f86d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-422f55fc-a4bd-4c76-961d-5382fd1f86d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-422f55fc-a4bd-4c76-961d-5382fd1f86d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
              "0       1     5000              1                    True   \n",
              "1       1   108590              1                   False   \n",
              "2       1     5000              0                   False   \n",
              "3       1     6692              1                   False   \n",
              "4       1   142590              1                   False   \n",
              "\n",
              "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
              "0                 False                False                False   \n",
              "1                 False                 True                False   \n",
              "2                 False                False                False   \n",
              "3                 False                 True                False   \n",
              "4                 False                 True                False   \n",
              "\n",
              "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
              "0                False                False                False  ...   \n",
              "1                False                False                False  ...   \n",
              "2                 True                False                False  ...   \n",
              "3                False                False                False  ...   \n",
              "4                False                False                False  ...   \n",
              "\n",
              "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0              False                   False                     False   \n",
              "1               True                   False                     False   \n",
              "2              False                   False                     False   \n",
              "3              False                    True                     False   \n",
              "4              False                   False                      True   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0               False             False                   False   \n",
              "1               False             False                   False   \n",
              "2               False             False                   False   \n",
              "3               False             False                   False   \n",
              "4               False             False                   False   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
              "0            False              False                      True   \n",
              "1            False              False                      True   \n",
              "2            False              False                      True   \n",
              "3            False              False                      True   \n",
              "4            False              False                      True   \n",
              "\n",
              "   SPECIAL_CONSIDERATIONS_Y  \n",
              "0                     False  \n",
              "1                     False  \n",
              "2                     False  \n",
              "3                     False  \n",
              "4                     False  \n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6nA-33tlTvY-"
      },
      "outputs": [],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "X = df_encoded.drop(columns=['IS_SUCCESSFUL'])\n",
        "y = df_encoded['IS_SUCCESSFUL']\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=46)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "R9CMDSNATvY-"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "muYqUndSTvY-"
      },
      "outputs": [],
      "source": [
        "# Convert X_train and y_train to NumPy arrays\n",
        "X_train = X_train.to_numpy().astype('float32')\n",
        "y_train = y_train.to_numpy().astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na_E5HL1TvY-"
      },
      "source": [
        "## Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "mD3T11K6TvY-",
        "outputId": "634c9139-249c-4584-f534-e9e0c62bf241"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,929</span> (19.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,929\u001b[0m (19.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,929</span> (19.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,929\u001b[0m (19.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = X_train.shape[1]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=64, activation='relu', input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9m_dVJWGTvY-"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-hPROJkTvY-",
        "outputId": "57cce1ed-ddc0-4979-b931-01c7b9ac24c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.4799 - loss: 40715.3711 - val_accuracy: 0.4692 - val_loss: 29790.4102\n",
            "Epoch 2/10\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4983 - loss: 46923.5273 - val_accuracy: 0.4692 - val_loss: 105165.7734\n",
            "Epoch 3/10\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4701 - loss: 31861.2520 - val_accuracy: 0.4692 - val_loss: 17534.8223\n",
            "Epoch 4/10\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4933 - loss: 15758.3525 - val_accuracy: 0.4692 - val_loss: 110284.6484\n",
            "Epoch 5/10\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4690 - loss: 36428.1992 - val_accuracy: 0.4692 - val_loss: 52733.5234\n",
            "Epoch 6/10\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4951 - loss: 36324.2188 - val_accuracy: 0.4692 - val_loss: 6381.2510\n",
            "Epoch 7/10\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5034 - loss: 40621.7812 - val_accuracy: 0.4692 - val_loss: 24735.0215\n",
            "Epoch 8/10\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4986 - loss: 41812.6445 - val_accuracy: 0.5308 - val_loss: 5300.0713\n",
            "Epoch 9/10\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4988 - loss: 14499.1201 - val_accuracy: 0.5088 - val_loss: 875.3863\n",
            "Epoch 10/10\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4926 - loss: 21360.0566 - val_accuracy: 0.5308 - val_loss: 585.9518\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = nn.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv7DfUFmTvY_",
        "outputId": "8850f748-e7da-47ab-b041-ecf5c4186d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - 2ms/step - accuracy: 0.6363 - loss: 1.1219\n",
            "Loss: 1.1218947172164917, Accuracy: 0.6362681984901428\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJD9BlxzTvY_",
        "outputId": "9828bf7b-789b-4c64-a305-6165f44e7945"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"NN_1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8xQELWlTvY_"
      },
      "outputs": [],
      "source": [
        "### Attempt #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "UFKA_kCmTvY_",
        "outputId": "d9076689-54fe-495a-a144-c405eb90b617"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m4,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,501</span> (37.11 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,501\u001b[0m (37.11 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,501</span> (37.11 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,501\u001b[0m (37.11 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = X_train.shape[1]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=100, activation='sigmoid', input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation='sigmoid'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sVhax8c9TvY_"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUqazAQVTvY_",
        "outputId": "5cfc208f-41b4-4af1-8ac6-6435e4a13742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5305 - loss: 0.6928 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 2/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5260 - loss: 0.6928 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 3/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5276 - loss: 0.6924 - val_accuracy: 0.5308 - val_loss: 0.6935\n",
            "Epoch 4/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5133 - loss: 0.6941 - val_accuracy: 0.5308 - val_loss: 0.6920\n",
            "Epoch 5/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5247 - loss: 0.6924 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 6/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5271 - loss: 0.6922 - val_accuracy: 0.5308 - val_loss: 0.6957\n",
            "Epoch 7/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5275 - loss: 0.6924 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 8/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 9/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5267 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6922\n",
            "Epoch 10/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5237 - loss: 0.6930 - val_accuracy: 0.5308 - val_loss: 0.6921\n",
            "Epoch 11/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5343 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 12/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5274 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 13/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5344 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 14/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 15/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6924\n",
            "Epoch 16/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5325 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 17/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5326 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 18/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5314 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6930\n",
            "Epoch 19/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5335 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 20/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5329 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 21/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5310 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 22/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5323 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 23/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5370 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 24/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5339 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 25/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5301 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 26/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5292 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6924\n",
            "Epoch 27/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5267 - loss: 0.6923 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 28/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5289 - loss: 0.6921 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 29/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5322 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 30/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5321 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 31/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5280 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 32/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5302 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 33/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5302 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 34/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5339 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6926\n",
            "Epoch 35/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5311 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 36/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 0.6921 - val_accuracy: 0.5308 - val_loss: 0.6918\n",
            "Epoch 37/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5302 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 38/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5298 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6923\n",
            "Epoch 39/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5328 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 40/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5278 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 41/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5316 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 42/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5318 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 43/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5344 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 44/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5313 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 45/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5351 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6919\n",
            "Epoch 46/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5342 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 47/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5345 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 48/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5331 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 49/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5304 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 50/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5343 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6921\n",
            "Epoch 51/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5303 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6919\n",
            "Epoch 52/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5248 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 53/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5332 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 54/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5318 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 55/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5326 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 56/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5315 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 57/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5336 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6920\n",
            "Epoch 58/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5275 - loss: 0.6924 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 59/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5324 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 60/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5321 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 61/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5315 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 62/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5312 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 63/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5330 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 64/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5326 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 65/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5342 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 66/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5345 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 67/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5347 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6922\n",
            "Epoch 68/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5296 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 69/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 70/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5293 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 71/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5322 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 72/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5374 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 73/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5345 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 74/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5299 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 75/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5333 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6920\n",
            "Epoch 76/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5341 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 77/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5355 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6918\n",
            "Epoch 78/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5270 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 79/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5368 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 80/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5317 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6921\n",
            "Epoch 81/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5306 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 82/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5358 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 83/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5337 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 84/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5306 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 85/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5326 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 86/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5315 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6922\n",
            "Epoch 87/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5339 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 88/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5276 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 89/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6921 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 90/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5303 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 91/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5328 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 92/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5337 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 93/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5349 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 94/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5365 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 95/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5302 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 96/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5322 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 97/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5353 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 98/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5339 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 99/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5301 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 100/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5360 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6916\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = nn.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVtBIoYyTvY_",
        "outputId": "14a1be03-191a-4c1b-c0a4-598307fca89c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - 1ms/step - accuracy: 0.5335 - loss: 0.6913\n",
            "Loss: 0.6913418769836426, Accuracy: 0.533527672290802\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCt0G7voTvZA",
        "outputId": "48b04d2b-e527-41a2-ba42-494bdc1d72b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"NN_2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gak4RahxTvZA"
      },
      "outputs": [],
      "source": [
        "#### Attempt #3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "L41bcK8XTvZA",
        "outputId": "0af94912-223f-4c47-f6dd-915c6f2549d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │           \u001b[38;5;34m8,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m20,100\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m101\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,001</span> (113.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,001\u001b[0m (113.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,001</span> (113.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,001\u001b[0m (113.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = X_train.shape[1]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=200, activation='tanh', input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=100, activation='tanh'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JP_VHEkdTvZA"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsnbtxVhTvZA",
        "outputId": "4dc0f53a-1eef-4854-bac7-1c79b507903c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5151 - loss: 0.7013 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 2/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5058 - loss: 0.6949 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 3/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5219 - loss: 0.6932 - val_accuracy: 0.5308 - val_loss: 0.6930\n",
            "Epoch 4/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5149 - loss: 0.6947 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 5/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5278 - loss: 0.6926 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 6/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5186 - loss: 0.6934 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 7/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5193 - loss: 0.6936 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 8/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5248 - loss: 0.6938 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 9/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5249 - loss: 0.6932 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 10/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5284 - loss: 0.6937 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 11/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5143 - loss: 0.6945 - val_accuracy: 0.4692 - val_loss: 0.6976\n",
            "Epoch 12/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5212 - loss: 0.6930 - val_accuracy: 0.5308 - val_loss: 0.7024\n",
            "Epoch 13/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5313 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6923\n",
            "Epoch 14/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5232 - loss: 0.6932 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 15/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5231 - loss: 0.6930 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 16/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5217 - loss: 0.6933 - val_accuracy: 0.5308 - val_loss: 0.7106\n",
            "Epoch 17/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5240 - loss: 0.6942 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 18/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5222 - loss: 0.6927 - val_accuracy: 0.4692 - val_loss: 0.6959\n",
            "Epoch 19/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5232 - loss: 0.6944 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 20/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5290 - loss: 0.6927 - val_accuracy: 0.4692 - val_loss: 0.6938\n",
            "Epoch 21/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5262 - loss: 0.6933 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 22/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5259 - loss: 0.6923 - val_accuracy: 0.5308 - val_loss: 0.6925\n",
            "Epoch 23/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5212 - loss: 0.6944 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 24/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5256 - loss: 0.6932 - val_accuracy: 0.5308 - val_loss: 0.6958\n",
            "Epoch 25/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5146 - loss: 0.6949 - val_accuracy: 0.4692 - val_loss: 0.6939\n",
            "Epoch 26/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5220 - loss: 0.6936 - val_accuracy: 0.5308 - val_loss: 0.6927\n",
            "Epoch 27/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5247 - loss: 0.6930 - val_accuracy: 0.5308 - val_loss: 0.6923\n",
            "Epoch 28/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5192 - loss: 0.6941 - val_accuracy: 0.5308 - val_loss: 0.6929\n",
            "Epoch 29/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.6933 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 30/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5289 - loss: 0.6929 - val_accuracy: 0.4692 - val_loss: 0.6952\n",
            "Epoch 31/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5145 - loss: 0.6933 - val_accuracy: 0.5308 - val_loss: 0.6942\n",
            "Epoch 32/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5143 - loss: 0.6930 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 33/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5222 - loss: 0.6935 - val_accuracy: 0.5308 - val_loss: 0.6922\n",
            "Epoch 34/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5198 - loss: 0.6929 - val_accuracy: 0.5308 - val_loss: 0.6929\n",
            "Epoch 35/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5314 - loss: 0.6924 - val_accuracy: 0.5308 - val_loss: 0.6954\n",
            "Epoch 36/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5326 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6918\n",
            "Epoch 37/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5316 - loss: 0.6923 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 38/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5184 - loss: 0.6936 - val_accuracy: 0.4692 - val_loss: 0.6959\n",
            "Epoch 39/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5158 - loss: 0.6935 - val_accuracy: 0.5308 - val_loss: 0.6931\n",
            "Epoch 40/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5237 - loss: 0.6934 - val_accuracy: 0.5308 - val_loss: 0.6982\n",
            "Epoch 41/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5215 - loss: 0.6933 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 42/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5313 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 43/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5107 - loss: 0.6939 - val_accuracy: 0.5308 - val_loss: 0.6977\n",
            "Epoch 44/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.6950 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 45/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5258 - loss: 0.6922 - val_accuracy: 0.4692 - val_loss: 0.6959\n",
            "Epoch 46/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 0.6929 - val_accuracy: 0.5308 - val_loss: 0.7014\n",
            "Epoch 47/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5258 - loss: 0.6932 - val_accuracy: 0.5308 - val_loss: 0.6923\n",
            "Epoch 48/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5207 - loss: 0.6945 - val_accuracy: 0.5308 - val_loss: 0.6973\n",
            "Epoch 49/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5189 - loss: 0.6933 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 50/50\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.6927 - val_accuracy: 0.5308 - val_loss: 0.6913\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = nn.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvlZvGipTvZA",
        "outputId": "f4596904-0e7e-4e8d-e18b-24e31690289d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - 2ms/step - accuracy: 0.5848 - loss: 0.6920\n",
            "Loss: 0.6920471787452698, Accuracy: 0.5848396420478821\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEgXcGskTvZA",
        "outputId": "b4284e47-a7d1-4924-e402-7d7059ffbe09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"NN_3.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM9xWNxGTvZA"
      },
      "outputs": [],
      "source": [
        "### Attempt #4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "dK2qvtFUTvZA",
        "outputId": "4f37504a-f174-4669-8ca1-632647e1c471"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">22,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">125,250</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">251</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │          \u001b[38;5;34m22,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)                 │         \u001b[38;5;34m125,250\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m251\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">147,501</span> (576.18 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m147,501\u001b[0m (576.18 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">147,501</span> (576.18 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m147,501\u001b[0m (576.18 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = X_train.shape[1]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=500, activation='relu', input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=250, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xSx2PciKTvZB"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spEgFlcaTvZB",
        "outputId": "4ca75134-fcc7-40be-b09d-f029d847e43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4977 - loss: 81129.1172 - val_accuracy: 0.5308 - val_loss: 39523.6836\n",
            "Epoch 2/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4794 - loss: 88126.3594 - val_accuracy: 0.5308 - val_loss: 25208.4922\n",
            "Epoch 3/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4950 - loss: 4213.8828 - val_accuracy: 0.4989 - val_loss: 1711.3965\n",
            "Epoch 4/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5182 - loss: 1580.7255 - val_accuracy: 0.5308 - val_loss: 800.6252\n",
            "Epoch 5/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.6255 - loss: 10.8837 - val_accuracy: 0.6379 - val_loss: 0.6402\n",
            "Epoch 6/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6432 - loss: 0.6299 - val_accuracy: 0.6389 - val_loss: 0.6364\n",
            "Epoch 7/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6380 - loss: 0.6358 - val_accuracy: 0.6443 - val_loss: 0.6365\n",
            "Epoch 8/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6457 - loss: 0.6332 - val_accuracy: 0.6443 - val_loss: 0.6348\n",
            "Epoch 9/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6531 - loss: 0.6281 - val_accuracy: 0.6461 - val_loss: 0.6338\n",
            "Epoch 10/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6527 - loss: 0.6303 - val_accuracy: 0.6457 - val_loss: 0.6372\n",
            "Epoch 11/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.6576 - loss: 0.6270 - val_accuracy: 0.6636 - val_loss: 0.6276\n",
            "Epoch 12/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6659 - loss: 0.6257 - val_accuracy: 0.6663 - val_loss: 0.6251\n",
            "Epoch 13/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6616 - loss: 0.6280 - val_accuracy: 0.6706 - val_loss: 0.6241\n",
            "Epoch 14/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.6113 - loss: 0.6526 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 15/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5305 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 16/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5323 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 17/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5329 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6918\n",
            "Epoch 18/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5325 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 19/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5303 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 20/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5335 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 21/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5286 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 22/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5307 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 23/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5317 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 24/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5359 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6919\n",
            "Epoch 25/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5385 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 26/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5286 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 27/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5299 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 28/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5279 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 29/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5300 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 30/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5349 - loss: 0.6913 - val_accuracy: 0.4692 - val_loss: 0.6939\n",
            "Epoch 31/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5248 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 32/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 33/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5304 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6933\n",
            "Epoch 34/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5288 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 35/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5332 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 36/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5359 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 37/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5364 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 38/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5299 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 39/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5282 - loss: 0.6922 - val_accuracy: 0.4692 - val_loss: 0.6935\n",
            "Epoch 40/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5231 - loss: 0.6929 - val_accuracy: 0.5308 - val_loss: 0.6920\n",
            "Epoch 41/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5253 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 42/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5273 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 43/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5295 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6923\n",
            "Epoch 44/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5310 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6918\n",
            "Epoch 45/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5214 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 46/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 47/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5271 - loss: 0.6921 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 48/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5290 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6931\n",
            "Epoch 49/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5291 - loss: 0.6921 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 50/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5350 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 51/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5305 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 52/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5284 - loss: 0.6921 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 53/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5351 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 54/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5332 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6920\n",
            "Epoch 55/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5313 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 56/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5280 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6922\n",
            "Epoch 57/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5353 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6921\n",
            "Epoch 58/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5267 - loss: 0.6921 - val_accuracy: 0.5308 - val_loss: 0.6925\n",
            "Epoch 59/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5328 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 60/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5311 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 61/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5199 - loss: 0.6924 - val_accuracy: 0.5308 - val_loss: 0.6920\n",
            "Epoch 62/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5335 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6920\n",
            "Epoch 63/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5317 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 64/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 65/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5187 - loss: 0.6924 - val_accuracy: 0.5308 - val_loss: 0.6929\n",
            "Epoch 66/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5365 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 67/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 68/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5354 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 69/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5323 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 70/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5325 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6929\n",
            "Epoch 71/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5275 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 72/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5331 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 73/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5299 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6918\n",
            "Epoch 74/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5277 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 75/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5388 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6923\n",
            "Epoch 76/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5292 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6933\n",
            "Epoch 77/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5332 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 78/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5363 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6926\n",
            "Epoch 79/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5252 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 80/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5274 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 81/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5265 - loss: 0.6922 - val_accuracy: 0.5308 - val_loss: 0.6925\n",
            "Epoch 82/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5347 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 83/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5352 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6918\n",
            "Epoch 84/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5292 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6919\n",
            "Epoch 85/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5287 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 86/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5299 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6923\n",
            "Epoch 87/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5318 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 88/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5370 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 89/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5316 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6927\n",
            "Epoch 90/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5351 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 91/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5299 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 92/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5337 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6927\n",
            "Epoch 93/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5363 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 94/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5334 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 95/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5350 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 96/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5329 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 97/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5393 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6927\n",
            "Epoch 98/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5234 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 99/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5341 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 100/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5338 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 101/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5330 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 102/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5346 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 103/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5315 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 104/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5372 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 105/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5296 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 106/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5308 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 107/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5339 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 108/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5344 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 109/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 110/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5314 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6919\n",
            "Epoch 111/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5344 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 112/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 113/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5293 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 114/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5313 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 115/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5319 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 116/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5315 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 117/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5302 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 118/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5320 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 119/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5232 - loss: 0.6921 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 120/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5359 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 121/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5366 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 122/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5295 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 123/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5318 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 124/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5304 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 125/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5337 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6918\n",
            "Epoch 126/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5368 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 127/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5289 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 128/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5297 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 129/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5286 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 130/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5338 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 131/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5308 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 132/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5348 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 133/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5372 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 134/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5290 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 135/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5306 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 136/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5329 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 137/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5223 - loss: 0.6921 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 138/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5361 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 139/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5291 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 140/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5318 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 141/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5329 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 142/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5347 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 143/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5349 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 144/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5287 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 145/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5303 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 146/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5317 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 147/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5285 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 148/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5378 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 149/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5340 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 150/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5319 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 151/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5308 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 152/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5332 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 153/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5343 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 154/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5323 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 155/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5319 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 156/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5304 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 157/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5331 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 158/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5337 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 159/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5316 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 160/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5337 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 161/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5334 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 162/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5281 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 163/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5341 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 164/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5363 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 165/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5322 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 166/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5363 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 167/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5334 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 168/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5327 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 169/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5316 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 170/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5316 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 171/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 172/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5306 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 173/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5321 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 174/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5316 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 175/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5289 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 176/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5280 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 177/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5350 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 178/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5306 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 179/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5302 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 180/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5377 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 181/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5343 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 182/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5322 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 183/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5329 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 184/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5262 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 185/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5343 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 186/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5245 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 187/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5335 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 188/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5323 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 189/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5300 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 190/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5281 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 191/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5339 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 192/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 193/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5379 - loss: 0.6903 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 194/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5360 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 195/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5294 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 196/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5267 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 197/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5371 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 198/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5323 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 199/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5348 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 200/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5355 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 201/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5310 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 202/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5353 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 203/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5355 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 204/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5288 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 205/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5293 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 206/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 207/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5362 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 208/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5337 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 209/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5353 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 210/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5301 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 211/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5352 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 212/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5295 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 213/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 214/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5338 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 215/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5294 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 216/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5272 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 217/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5286 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 218/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5293 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 219/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5290 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 220/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5321 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 221/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5327 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 222/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5338 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 223/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5297 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 224/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5280 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 225/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5310 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 226/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5281 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 227/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5375 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 228/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5275 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 229/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5270 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 230/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5357 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 231/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5232 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 232/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5292 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 233/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5366 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 234/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5347 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 235/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5323 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 236/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5278 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 237/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 238/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5345 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 239/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5290 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 240/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5334 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 241/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5356 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 242/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5345 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 243/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5340 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 244/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5225 - loss: 0.6923 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 245/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5260 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 246/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5316 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 247/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5395 - loss: 0.6901 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 248/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5305 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 249/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5313 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 250/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5332 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 251/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5297 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 252/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5334 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 253/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 254/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5355 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 255/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 256/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5387 - loss: 0.6902 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 257/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5377 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 258/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5383 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 259/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5306 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 260/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5310 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 261/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5297 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 262/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5292 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 263/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5291 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 264/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5325 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 265/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5271 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 266/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5380 - loss: 0.6903 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 267/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5309 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 268/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5383 - loss: 0.6903 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 269/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5315 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 270/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5391 - loss: 0.6902 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 271/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5303 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 272/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5419 - loss: 0.6898 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 273/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5327 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 274/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5343 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 275/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5327 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 276/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5356 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 277/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5350 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 278/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5331 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 279/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5360 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 280/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5307 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 281/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5278 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 282/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5358 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 283/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5320 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 284/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5373 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 285/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5275 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 286/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5331 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 287/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 288/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5350 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 289/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5377 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 290/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5354 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 291/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5325 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 292/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5352 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 293/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5304 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 294/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5335 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 295/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5304 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 296/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5308 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 297/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5278 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 298/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5298 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 299/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5339 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 300/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5359 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 301/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5319 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 302/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5320 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 303/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5400 - loss: 0.6900 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 304/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5318 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 305/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5349 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 306/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5378 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 307/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5293 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 308/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5366 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 309/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5265 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 310/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5343 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 311/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5308 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 312/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5360 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 313/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5357 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 314/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5357 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 315/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5278 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 316/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5397 - loss: 0.6901 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 317/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5332 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 318/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5342 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 319/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5321 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 320/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5359 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 321/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5324 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 322/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5398 - loss: 0.6901 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 323/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.5340 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 324/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5328 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 325/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5314 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 326/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5361 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 327/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5380 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 328/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5347 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 329/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5323 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 330/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 331/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5310 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 332/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5306 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 333/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5402 - loss: 0.6900 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 334/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5323 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 335/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5384 - loss: 0.6903 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 336/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5279 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 337/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5335 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 338/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5312 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 339/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5313 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 340/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5359 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 341/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5366 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 342/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5365 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 343/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5367 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 344/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 345/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 346/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5310 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 347/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5371 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 348/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5276 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 349/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5323 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 350/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 351/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5372 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 352/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5339 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 353/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5338 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 354/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5316 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 355/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5333 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 356/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5307 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 357/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5306 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 358/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5265 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 359/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5356 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 360/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5316 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 361/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5320 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 362/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5307 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 363/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 364/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5329 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 365/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5352 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 366/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5361 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 367/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5356 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 368/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5286 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 369/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5317 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 370/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5333 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 371/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5325 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 372/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5353 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 373/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5282 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 374/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5366 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 375/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5378 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 376/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5323 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 377/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5318 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 378/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5324 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 379/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5305 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 380/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5361 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 381/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5355 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 382/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5325 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 383/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5347 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 384/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5312 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 385/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5269 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 386/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5353 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 387/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5323 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 388/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5360 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 389/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5352 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 390/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5304 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 391/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5340 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 392/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5361 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 393/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5301 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 394/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5361 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 395/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5278 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 396/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5260 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 397/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5302 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 398/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5344 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 399/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5283 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 400/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5289 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 401/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5324 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 402/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5308 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 403/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5336 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 404/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5300 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 405/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5282 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 406/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5274 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 407/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5259 - loss: 0.6920 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 408/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5304 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 409/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5267 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 410/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5339 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 411/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5352 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 412/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5411 - loss: 0.6899 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 413/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5435 - loss: 0.6897 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 414/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5299 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 415/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5355 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 416/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5299 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 417/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5317 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 418/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5381 - loss: 0.6903 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 419/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5351 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 420/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5303 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 421/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 422/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5341 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 423/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5261 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 424/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5334 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 425/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5364 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 426/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5333 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 427/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5316 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 428/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5291 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 429/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5252 - loss: 0.6921 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 430/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5286 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 431/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5301 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 432/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5338 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 433/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5304 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 434/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5331 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 435/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5295 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 436/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5293 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 437/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5346 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 438/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5340 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 439/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5329 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 440/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5350 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 441/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5381 - loss: 0.6903 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 442/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5362 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 443/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5252 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 444/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5332 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 445/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5298 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 446/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5364 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 447/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5356 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 448/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5341 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 449/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5364 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 450/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5344 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 451/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5338 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 452/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5369 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 453/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5276 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 454/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5311 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 455/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5317 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 456/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5320 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 457/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5327 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 458/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5301 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 459/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5266 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 460/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5331 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 461/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5387 - loss: 0.6903 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 462/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5272 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 463/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5304 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 464/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5357 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 465/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5320 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 466/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5308 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 467/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5282 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 468/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5381 - loss: 0.6903 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 469/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5362 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 470/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5300 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 471/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5275 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 472/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5267 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 473/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5305 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 474/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5371 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 475/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 476/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5346 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 477/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5294 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 478/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5383 - loss: 0.6903 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 479/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5290 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 480/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5311 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 481/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5346 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 482/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.5393 - loss: 0.6902 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 483/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5303 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 484/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5328 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 485/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.5286 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 486/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5334 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 487/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5390 - loss: 0.6902 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 488/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5281 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 489/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5315 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 490/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5370 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 491/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5344 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 492/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5345 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 493/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5366 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 494/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5309 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 495/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5317 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 496/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5297 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 497/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5281 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 498/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5272 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 499/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.5331 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 500/500\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5277 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = nn.fit(X_train, y_train, epochs=500, batch_size=20, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdXxv63eTvZB",
        "outputId": "50e7fb94-4dc6-4766-86c8-8215f0d47d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 1s - 2ms/step - accuracy: 0.4184 - loss: 2.4279\n",
            "Loss: 2.427924156188965, Accuracy: 0.41842564940452576\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4etpTRlTvZC",
        "outputId": "40935045-765e-4864-b5c4-bdc08ca46005"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"NN_4.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnNmGGybnXpd"
      },
      "outputs": [],
      "source": [
        "### Attempt #5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "qAYbrpvtnXsV",
        "outputId": "a1089096-dc8d-4fec-e914-76034bfc7492"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m2,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │           \u001b[38;5;34m1,275\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m26\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,501</span> (13.68 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,501\u001b[0m (13.68 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,501</span> (13.68 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,501\u001b[0m (13.68 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = X_train.shape[1]\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=50, activation='relu', input_dim=number_input_features))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=25, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lL8Adb0NnXvA"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRlDF6NsnXxz",
        "outputId": "d2f89672-7f58-42fe-80c3-493a4719a822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4844 - loss: 26839.6094 - val_accuracy: 0.5308 - val_loss: 118012.0703\n",
            "Epoch 2/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5079 - loss: 129493.0547 - val_accuracy: 0.5308 - val_loss: 449.7777\n",
            "Epoch 3/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5006 - loss: 11895.6191 - val_accuracy: 0.4692 - val_loss: 12548.9014\n",
            "Epoch 4/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4951 - loss: 5605.2192 - val_accuracy: 0.4692 - val_loss: 6471.6562\n",
            "Epoch 5/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4977 - loss: 11280.1055 - val_accuracy: 0.4692 - val_loss: 15919.6484\n",
            "Epoch 6/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4955 - loss: 33619.6758 - val_accuracy: 0.5034 - val_loss: 822.1902\n",
            "Epoch 7/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5230 - loss: 2012.7997 - val_accuracy: 0.5308 - val_loss: 106538.2656\n",
            "Epoch 8/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5263 - loss: 77538.2266 - val_accuracy: 0.4692 - val_loss: 3088.5212\n",
            "Epoch 9/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5218 - loss: 10557.9746 - val_accuracy: 0.5308 - val_loss: 28126.0137\n",
            "Epoch 10/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5206 - loss: 3673.0439 - val_accuracy: 0.4692 - val_loss: 2385.6479\n",
            "Epoch 11/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5072 - loss: 5322.0781 - val_accuracy: 0.4692 - val_loss: 9124.2920\n",
            "Epoch 12/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4927 - loss: 9563.2803 - val_accuracy: 0.4692 - val_loss: 30105.4219\n",
            "Epoch 13/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4980 - loss: 21735.4219 - val_accuracy: 0.5207 - val_loss: 127.1551\n",
            "Epoch 14/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5222 - loss: 6203.8579 - val_accuracy: 0.5302 - val_loss: 28.5532\n",
            "Epoch 15/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5472 - loss: 1252.9956 - val_accuracy: 0.6461 - val_loss: 787.5784\n",
            "Epoch 16/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5348 - loss: 2532.3933 - val_accuracy: 0.6080 - val_loss: 482.7866\n",
            "Epoch 17/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5026 - loss: 10427.7559 - val_accuracy: 0.4692 - val_loss: 16778.1016\n",
            "Epoch 18/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5014 - loss: 3205.7458 - val_accuracy: 0.6338 - val_loss: 1508.6600\n",
            "Epoch 19/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5108 - loss: 1493.4352 - val_accuracy: 0.5308 - val_loss: 1930.8192\n",
            "Epoch 20/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4979 - loss: 2507.0479 - val_accuracy: 0.5071 - val_loss: 71.8511\n",
            "Epoch 21/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4799 - loss: 1432.3099 - val_accuracy: 0.5308 - val_loss: 5552.8755\n",
            "Epoch 22/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5061 - loss: 1200.5912 - val_accuracy: 0.5308 - val_loss: 1529.9801\n",
            "Epoch 23/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5071 - loss: 6629.2300 - val_accuracy: 0.4692 - val_loss: 2686.9233\n",
            "Epoch 24/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5053 - loss: 1241.7605 - val_accuracy: 0.4692 - val_loss: 2690.6204\n",
            "Epoch 25/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4926 - loss: 513.7027 - val_accuracy: 0.4692 - val_loss: 922.1349\n",
            "Epoch 26/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5010 - loss: 3307.1475 - val_accuracy: 0.5102 - val_loss: 127.6045\n",
            "Epoch 27/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4936 - loss: 309.6536 - val_accuracy: 0.5308 - val_loss: 0.9440\n",
            "Epoch 28/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5312 - loss: 0.8334 - val_accuracy: 0.5308 - val_loss: 0.6981\n",
            "Epoch 29/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5292 - loss: 0.6950 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 30/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5307 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6904\n",
            "Epoch 31/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5640 - loss: 0.6699 - val_accuracy: 0.6507 - val_loss: 0.6335\n",
            "Epoch 32/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5837 - loss: 0.6599 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 33/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5380 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 34/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5347 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 35/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5334 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 36/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5326 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 37/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5324 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 38/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5344 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 39/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5375 - loss: 0.6905 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 40/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5299 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 41/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5344 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 42/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5368 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 43/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5279 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 44/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5422 - loss: 0.6897 - val_accuracy: 0.5308 - val_loss: 0.6918\n",
            "Epoch 45/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5344 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 46/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5344 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 47/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5313 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 48/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5265 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 49/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5317 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 50/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5346 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 51/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5246 - loss: 0.6925 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 52/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5355 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 53/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5366 - loss: 0.6907 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 54/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5325 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 55/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5322 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 56/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5383 - loss: 0.6906 - val_accuracy: 0.5308 - val_loss: 0.6920\n",
            "Epoch 57/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5335 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 58/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5278 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 59/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5282 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 60/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5325 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 61/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5344 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 62/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5335 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 63/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5283 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 64/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 65/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5405 - loss: 0.6900 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 66/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5338 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 67/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 68/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5315 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 69/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5332 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6912\n",
            "Epoch 70/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5310 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 71/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5271 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6943\n",
            "Epoch 72/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5328 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 73/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5337 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 74/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5313 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 75/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5302 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 76/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5318 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 77/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 78/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5298 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 79/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5359 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 80/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 81/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5385 - loss: 0.6904 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 82/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5345 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 83/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5318 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 84/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5292 - loss: 0.6917 - val_accuracy: 0.5308 - val_loss: 0.6920\n",
            "Epoch 85/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5295 - loss: 0.6919 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 86/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5319 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 87/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5303 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 88/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5362 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 89/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5330 - loss: 0.6912 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 90/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5361 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6915\n",
            "Epoch 91/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5352 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 92/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5340 - loss: 0.6910 - val_accuracy: 0.5308 - val_loss: 0.6917\n",
            "Epoch 93/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5305 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6914\n",
            "Epoch 94/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5294 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 95/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 96/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5433 - loss: 0.6895 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 97/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5345 - loss: 0.6911 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 98/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5262 - loss: 0.6918 - val_accuracy: 0.5308 - val_loss: 0.6913\n",
            "Epoch 99/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5308 - loss: 0.6915 - val_accuracy: 0.5308 - val_loss: 0.6916\n",
            "Epoch 100/100\n",
            "\u001b[1m1029/1029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5269 - loss: 0.6922 - val_accuracy: 0.5308 - val_loss: 0.6913\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = nn.fit(X_train, y_train, epochs=100, batch_size=20, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VipZKDlHnX06",
        "outputId": "d3de144b-5d04-48e9-f61a-8b87c7bcf142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - 2ms/step - accuracy: 0.6762 - loss: 1.1591\n",
            "Loss: 1.1590691804885864, Accuracy: 0.6761516332626343\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL5AJ0ednX3v",
        "outputId": "2971f78f-ad2a-432c-bcb0-1d0fd2d026a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "nn.save(\"NN_5.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
